{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296ca8a1-250a-4694-bcac-ae47ebb60e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 23:25:08.045310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755750308.067725 3789183 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755750308.075321 3789183 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-20 23:25:08.103482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import skrf as rf\n",
    "from scipy.spatial import distance\n",
    "from scipy.linalg import eigh\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "import math, random, functools\n",
    "from typing import Optional, Dict, Tuple\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78139a91-cc16-49b6-87f4-fa888c0d5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the targeted max frequency\n",
    "fmax = 200\n",
    "#define function for loading ind and s-parameters\n",
    "#\"path\" is the path for ind of transformer layout\n",
    "#\"label\" is the path for labels. In this case, labels are S-parameter associated with each ind \n",
    "def load_ind_from_path_MxN(path, label,length):\n",
    "    ind_a = []\n",
    "    ind_b = []\n",
    "    labels = []\n",
    "    error = []\n",
    "    for kk in range(length):\n",
    "        #load ind\n",
    "        ind = np.load(path+str(kk)+'.npz')\n",
    "        result_a = []\n",
    "        result_b = []\n",
    "        dst_a = np.zeros(len(ind['a'])-1)\n",
    "        aj_a = np.zeros((len(ind['a']),len(ind['a'])))\n",
    "        dst_b = np.zeros(len(ind['b'])-1)\n",
    "        aj_b = np.zeros((len(ind['b']),len(ind['b'])))\n",
    "        \n",
    "        for x in range(len(ind['a'])-1):\n",
    "            dst = distance.euclidean(ind['a'][x],ind['a'][x+1])\n",
    "            dst_a[x] = dst\n",
    "            aj_a[x][x+1] = dst_a[x]\n",
    "            aj_a[x+1][x] = dst_a[x]\n",
    "        \n",
    "        eigenvalues, eigenvectors = eigh(aj_a)\n",
    "        \n",
    "        for x in range(int(np.ceil(len(ind['a'])/2))):\n",
    "            result_a.append([ind['a'][x][0]/100,ind['a'][x][1]/100,ind['a'][x+1][0]/100,ind['a'][x+1][1]/100,dst_a[x]/100,0,np.sum(eigenvectors[x][1]+eigenvectors[x+1][1])])\n",
    "        ind_a.append(result_a)\n",
    "        \n",
    "        for x in range(len(ind['b'])-1):\n",
    "            dst = distance.euclidean(ind['b'][x],ind['b'][x+1])\n",
    "            dst_b[x] = dst\n",
    "            aj_b[x][x+1] = dst_b[x]\n",
    "            aj_b[x+1][x] = dst_b[x]\n",
    "        \n",
    "        eigenvalues, eigenvectors = eigh(aj_b)\n",
    "        \n",
    "        for x in range(int(np.ceil(len(ind['b'])/2))):\n",
    "            result_b.append([ind['b'][x][0]/100,ind['b'][x][1]/100,ind['b'][x+1][0]/100,ind['b'][x+1][1]/100,dst_b[x]/100,0,np.sum(eigenvectors[x][1]+eigenvectors[x+1][1])])\n",
    "        ind_b.append(result_b)\n",
    "        #load S-parameters\n",
    "        #According to symmerty, only S11,S12,S13,S14,S33,S34 are considered\n",
    "        #Each S-parameter has real and imaginary parts, and hence 12 real values in total.\n",
    "        results = []\n",
    "        datafile = label+str(kk)+\".s4p\"\n",
    "        spt = rf.Network(datafile)\n",
    "        step = int(1e9/(spt.f[1]-spt.f[0]))\n",
    "        for k in range(fmax+1):\n",
    "            i = int(k*step/2)\n",
    "            results.append([spt.s[i][0][0].real,spt.s[i][0][0].imag,\n",
    "                            spt.s[i][0][1].real,spt.s[i][0][1].imag,\n",
    "                            spt.s[i][0][2].real,spt.s[i][0][2].imag,\n",
    "                            spt.s[i][0][3].real,spt.s[i][0][3].imag,\n",
    "                            spt.s[i][2][2].real,spt.s[i][2][2].imag,\n",
    "                            spt.s[i][2][3].real,spt.s[i][2][3].imag])     \n",
    "        sp = np.array(results)\n",
    "        invalid = False\n",
    "        '''\n",
    "        for k in range(len(sp)-3):\n",
    "            for x in range(12):\n",
    "                if abs(sp[k][x]+sp[k+2][x]-2*sp[k+1][x])>0.03:\n",
    "                    invalid = True\n",
    "                    '''\n",
    "        if (invalid):\n",
    "            error.append(kk)\n",
    "        labels.append(results) \n",
    "    return ind_a,ind_b, labels,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774ac0cf-96d6-4a93-a1dc-26a6e188cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ind_from_path(path, label,length):\n",
    "    ind_a = []\n",
    "    ind_b = []\n",
    "    labels = []\n",
    "    error = []\n",
    "    for kk in range(length):\n",
    "        result_a = []\n",
    "        result_b = []\n",
    "        #load ind\n",
    "        file_path = (path+str(kk)+'.pkl')\n",
    "        with open(file_path, 'rb') as f:\n",
    "            loaded_list = pickle.load(f)\n",
    "        totalD = loaded_list[0]\n",
    "        node_D = []\n",
    "        for item in totalD:\n",
    "            wid = item[0]\n",
    "            layer = item[1]\n",
    "            for node in item[2]:\n",
    "                node_D.append(node)\n",
    "        #print(np.shape(node_D))\n",
    "        node_D = list(dict.fromkeys(node_D))\n",
    "        #print(np.shape(node_D))\n",
    "        inda_node = np.array(node_D)\n",
    "        #print(np.shape(inda_node))\n",
    "        totalU = loaded_list[1]\n",
    "        node_U = []\n",
    "        for item in totalD:\n",
    "            wid = item[0]\n",
    "            layer = item[1]\n",
    "            for node in item[2]:\n",
    "                node_U.append(node)\n",
    "        node_U = list(dict.fromkeys(node_U))\n",
    "        indb_node = np.array(node_U)\n",
    "        dst_a = np.zeros(len(inda_node)-1)\n",
    "        aj_a = np.zeros((len(inda_node),len(inda_node)))\n",
    "        dst_b = np.zeros(len(indb_node)-1)\n",
    "        aj_b = np.zeros((len(indb_node),len(indb_node)))\n",
    "        \n",
    "        for x in range(len(inda_node)-1):\n",
    "            dst = distance.euclidean(inda_node[x],inda_node[x+1])\n",
    "            dst_a[x] = dst\n",
    "            aj_a[x][x+1] = dst_a[x]\n",
    "            aj_a[x+1][x] = dst_a[x]\n",
    "        \n",
    "        eigenvalues, eigenvectors = eigh(aj_a)\n",
    "        \n",
    "        for x in range(len(inda_node)-1):\n",
    "            if(inda_node[x+1][0]==15) or (inda_node[x+1][0]==-15):\n",
    "                continue\n",
    "            result_a.append([inda_node[x][0]/100,inda_node[x][1]/100,inda_node[x+1][0]/100,inda_node[x+1][1]/100,dst_a[x]/100,0,np.sum(eigenvectors[x][1]+eigenvectors[x+1][1])])\n",
    "        ind_a.append(result_a)\n",
    "        \n",
    "        for x in range(len(indb_node)-1):\n",
    "            dst = distance.euclidean(indb_node[x],indb_node[x+1])\n",
    "            dst_b[x] = dst\n",
    "            aj_b[x][x+1] = dst_b[x]\n",
    "            aj_b[x+1][x] = dst_b[x]\n",
    "        \n",
    "        eigenvalues, eigenvectors = eigh(aj_b)\n",
    "        \n",
    "        for x in range(len(indb_node)-1):\n",
    "            if(indb_node[x+1][0]==15) or (indb_node[x+1][0]==-15):\n",
    "                continue\n",
    "            result_b.append([indb_node[x][0]/100,indb_node[x][1]/100,indb_node[x+1][0]/100,indb_node[x+1][1]/100,dst_b[x]/100,0,np.sum(eigenvectors[x][1]+eigenvectors[x+1][1])])\n",
    "        ind_b.append(result_b)\n",
    "        #load S-parameters\n",
    "        #According to symmerty, only S11,S12,S13,S14,S33,S34 are considered\n",
    "        #Each S-parameter has real and imaginary parts, and hence 12 real values in total.\n",
    "        results = []\n",
    "        datafile = label+str(kk)+\".s4p\"\n",
    "        spt = rf.Network(datafile)\n",
    "        step = int(1e9/(spt.f[1]-spt.f[0]))\n",
    "        for k in range(fmax+1):\n",
    "            i = k*step\n",
    "            results.append([spt.s[i][0][0].real,spt.s[i][0][0].imag,\n",
    "                            spt.s[i][0][1].real,spt.s[i][0][1].imag,\n",
    "                            spt.s[i][0][2].real,spt.s[i][0][2].imag,\n",
    "                            spt.s[i][0][3].real,spt.s[i][0][3].imag,\n",
    "                            spt.s[i][2][2].real,spt.s[i][2][2].imag,\n",
    "                            spt.s[i][2][3].real,spt.s[i][2][3].imag])     \n",
    "        sp = np.array(results)\n",
    "        invalid = False\n",
    "        '''\n",
    "        for k in range(len(sp)-3):\n",
    "            for x in range(12):\n",
    "                if abs(sp[k][x]+sp[k+2][x]-2*sp[k+1][x])>0.03:\n",
    "                    invalid = True\n",
    "                    '''\n",
    "        if (invalid):\n",
    "            error.append(kk)\n",
    "        labels.append(results) \n",
    "    return ind_a,ind_b, labels,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee37838f-7e21-4c05-8a30-b9ef657ae102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path_MxN(path):\n",
    "    logfile = open(path+\"log.txt\",\"r\")\n",
    "    listall = list(map(lambda item: list(map(lambda jtem: eval(jtem.strip()), item[1:-1].split(','))), logfile.read().strip().split('\\n')))\n",
    "    tabular_data = np.array(listall)\n",
    "\n",
    "#load images and s-parameters\n",
    "    length = len(tabular_data)\n",
    "    ind_a, ind_b,labels,error = load_ind_from_path_MxN(path+\"SEG/\", path+\"SPData/\",length)\n",
    "\n",
    "    #show_images(images)\n",
    "    srf = np.load(path+\"/srf.npy\")\n",
    "\n",
    "    for kk in range(length):\n",
    "        if kk in error:\n",
    "            continue  \n",
    "    #select 1 turn and 1 turn transformers\n",
    "        if((tabular_data[kk,2]!=0) or (tabular_data[kk,3]!=0)):\n",
    "       #b only includes the variable parameters in our designs. \n",
    "       #Constants at this design stages are excluded\n",
    "            for i in range(len(ind_a[kk])):\n",
    "                ind_a[kk][i][5] = tabular_data[kk][6]\n",
    "            for i in range(len(ind_b[kk])):\n",
    "                ind_b[kk][i][5] = tabular_data[kk][7]\n",
    "            ind_a11.append(np.array(ind_a[kk]))\n",
    "            ind_b11.append(np.array(ind_b[kk]))\n",
    "            labels11.append(labels[kk])\n",
    "            srf_list.append(srf[kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a00f97-6f50-4f72-99f3-38115eef0419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path_parallel(path):\n",
    "    logfile = open(path+\"log.txt\",\"r\")\n",
    "    listall = list(map(lambda item: list(map(lambda jtem: eval(jtem.strip()), item[1:-1].split(','))), logfile.read().strip().split('\\n')))\n",
    "    tabular_data = np.array(listall)\n",
    "\n",
    "#load images and s-parameters\n",
    "    length = len(tabular_data)\n",
    "    ind_a, ind_b,labels,error = load_ind_from_path(path+\"SEG/\", path+\"SPData/\",length)\n",
    "\n",
    "    #show_images(images)\n",
    "    srf = np.load('/rdf/shared/design_automation/Data_EMX/XFMRParallel_2504/srf.npy')\n",
    "    for kk in range(length):\n",
    "        if kk in error:\n",
    "            continue  \n",
    "        #select 1 turn and 1 turn transformers\n",
    "        if((tabular_data[kk,4]!=0) and (tabular_data[kk,5]!=0)):\n",
    "           #b only includes the variable parameters in our designs. \n",
    "           #Constants at this design stages are excluded\n",
    "            for i in range(len(ind_a[kk])):\n",
    "                ind_a[kk][i][5] = tabular_data[kk][4]\n",
    "            for i in range(len(ind_b[kk])):\n",
    "                ind_b[kk][i][5] = tabular_data[kk][4]\n",
    "            ind_a11.append(np.array(ind_a[kk]))\n",
    "            ind_b11.append(np.array(ind_b[kk]))\n",
    "            labels11.append(labels[kk])\n",
    "            srf_list.append(srf[kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7cd456-0d38-417a-8d70-7cb5fbbfefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path_8shaped(path):\n",
    "    logfile = open(path+\"log.txt\",\"r\")\n",
    "    listall = list(map(lambda item: list(map(lambda jtem: eval(jtem.strip()), item[1:-1].split(','))), logfile.read().strip().split('\\n')))\n",
    "    tabular_data = np.array(listall)\n",
    "\n",
    "#load images and s-parameters\n",
    "    length = len(tabular_data)\n",
    "    ind_a, ind_b,labels,error = load_ind_from_path(path+\"SEG/\", path+\"SPData/\",length)\n",
    "\n",
    "    #show_images(images)\n",
    "    srf = np.load('/rdf/shared/design_automation/Data_EMX/XFMR8Shaped1x2_2504/srf.npy')\n",
    "    for kk in range(length):\n",
    "        if kk in error:\n",
    "            continue  \n",
    "        #select 1 turn and 1 turn transformers\n",
    "        if((tabular_data[kk,4]!=0) and (tabular_data[kk,5]!=0)):\n",
    "           #b only includes the variable parameters in our designs. \n",
    "           #Constants at this design stages are excluded\n",
    "            for i in range(len(ind_a[kk])):\n",
    "                ind_a[kk][i][5] = tabular_data[kk][4]\n",
    "            for i in range(len(ind_b[kk])):\n",
    "                ind_b[kk][i][5] = tabular_data[kk][4]\n",
    "            ind_a11.append(np.array(ind_a[kk]))\n",
    "            ind_b11.append(np.array(ind_b[kk]))\n",
    "            labels11.append(labels[kk])\n",
    "            srf_list.append(srf[kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c5ae31-1f0f-45d6-a298-1963e2aa8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_a11 = []\n",
    "ind_b11 = []\n",
    "labels11 = []\n",
    "srf_list = []\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        path = \"/rdf/shared/design_automation/Data_EMX/XFMR_2503_\"+str(i+1)+\"x\"+str(j+1)+\"/\"\n",
    "        load_from_path_MxN(path)\n",
    "\n",
    "path = '/rdf/shared/design_automation/Data_EMX/XFMRParallel_2504/'\n",
    "load_from_path_parallel(path)\n",
    "\n",
    "path = '/rdf/shared/design_automation/Data_EMX/XFMR8Shaped1x2_2504/'\n",
    "load_from_path_8shaped(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48486e52-a293-4c20-8f7a-ce78886418d9",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da37382-d586-4137-a71b-3754b4a7aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "d_model = 32\n",
    "num_heads = 4\n",
    "dff = 256\n",
    "num_layers = 2\n",
    "max_seq_len = 32\n",
    "height = 7\n",
    "dropout_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55dea77-5a73-4c4a-8a25-063c9c7962f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Positional Encoding\n",
    "#################################\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_len, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        positions = torch.arange(seq_len).unsqueeze(1).float()  # [seq_len, 1]\n",
    "        dims = torch.arange(d_model).unsqueeze(0).float()  # [1, d_model]\n",
    "\n",
    "        angle_rates = 1 / torch.pow(10000.0, (2 * (dims // 2)) / d_model)\n",
    "        angle_rads = positions * angle_rates\n",
    "\n",
    "        # Compute sine and cosine\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # Concatenate sine and cosine\n",
    "        pos_encoding = torch.cat([sines, cosines], dim=-1)  # [seq_len, d_model]\n",
    "        self.pos_encoding = pos_encoding.unsqueeze(0)  # [1, seq_len, d_model]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pos_encoding[:, :x.size(1), :].to(x.device)\n",
    "\n",
    "#################################\n",
    "# Padding Mask\n",
    "#################################\n",
    "def create_padding_mask(x):\n",
    "    \"\"\"\n",
    "    Compute the padding mask:\n",
    "    - x: [batch_size, seq_len, height]\n",
    "    - mask: [batch_size, 1, 1, seq_len]\n",
    "    \"\"\"\n",
    "    summed = torch.sum(torch.abs(x), dim=2)  # [batch_size, seq_len]\n",
    "    mask = (summed == 0).float()  # 1.0 indicates padding\n",
    "     # Expand mask to match MultiheadAttention expected shape\n",
    "    mask = mask[:, None, None, :]  # Shape: [batch_size, 1, 1, seq_len]\n",
    "    \n",
    "    # Reshape to [batch_size * num_heads, seq_len, seq_len]\n",
    "    batch_size, seq_len, height = x.shape\n",
    "    mask = mask.expand(batch_size, num_heads, seq_len, seq_len)  # [batch_size, num_heads, seq_len, seq_len] \n",
    "    # Merge batch_size and num_heads into the first dimension\n",
    "    mask = mask.reshape(batch_size * num_heads, seq_len, seq_len)\n",
    "    return mask\n",
    "\n",
    "\n",
    "#################################\n",
    "# Example Usage\n",
    "#################################\n",
    "# Creating a batch of variable-length sequences with each element being a vector of length 'height'.\n",
    "# For demonstration:\n",
    "# Sequence 1: length=4\n",
    "# Sequence 2: length=7\n",
    "# Sequence 3: length=3\n",
    "# We'll pad them to length=7.\n",
    "\n",
    "def pad_sequence(seq_len, max_len=7):\n",
    "    length = seq_len.shape[0]\n",
    "    pad_len = max_len - length\n",
    "    return torch.cat([seq_len, torch.zeros(pad_len, height)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcee994d-b2c7-430f-ae80-892609d844fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(seq) for seq in ind_b11)\n",
    "max_len = int(max_len) \n",
    "\n",
    "new_a = []\n",
    "for a in ind_a11:\n",
    "    padded_a = pad_sequence(torch.tensor(a, dtype=torch.float32),max_len)\n",
    "    new_a.append(padded_a.detach().numpy())\n",
    "#transformer_encoder.eval()  # Set to evaluation mode\n",
    "#transformer_encoder = TransformerEncoder(num_layers, d_model, num_heads, dff, max_seq_len)\n",
    "#output = transformer_encoder(torch.stack(new_a))\n",
    "#print(\"Output shape:\", output.shape)  # [batch_size, seq_len, d_model]\n",
    "new_b = []\n",
    "for b in ind_b11:\n",
    "    padded_b = pad_sequence(torch.tensor(b, dtype=torch.float32),max_len)\n",
    "    new_b.append(padded_b.detach().numpy())\n",
    "\n",
    "class item:\n",
    "  def __init__(self, a,b,label,srf):\n",
    "    self.a = a\n",
    "    self.b = b\n",
    "    self.label = label\n",
    "    self.srf = srf\n",
    "data = []\n",
    "for i in range(len(ind_a11)):\n",
    "    data.append(item(new_a[i],new_b[i],labels11[i],srf_list[i]))\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "length = len(ind_a11)\n",
    "split1 = int(0.6*length)\n",
    "split2 = int(0.8*length)\n",
    "data_train = data[0:split1]\n",
    "data_valid = data[split1:split2]\n",
    "data_test = data[split2:]\n",
    "\n",
    "#Separate the training, validation and test datasets \n",
    "train_a = []\n",
    "train_labels = []\n",
    "train_b = []\n",
    "train_srf = []\n",
    "valid_a = []\n",
    "valid_labels = []\n",
    "valid_b = []\n",
    "valid_srf = []\n",
    "test_a = []\n",
    "test_labels = []\n",
    "test_b = []\n",
    "test_srf = []\n",
    "\n",
    "#The targeted frequency span up to fmax, with 1GHz step\n",
    "s_max = np.zeros((fmax,12))\n",
    "s_min = np.zeros((fmax,12))\n",
    "srange = np.zeros((fmax,12))\n",
    "\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    train_a.append(data_train[i].a)\n",
    "    train_b.append(data_train[i].b)\n",
    "    train_labels.append(data_train[i].label)\n",
    "    train_srf.append(data_train[i].srf)\n",
    "x_train_a = np.array(train_a) \n",
    "x_train_b = np.array(train_b)\n",
    "x_train_srf = np.array(train_srf)\n",
    "y_train_encoded = np.array(train_labels)[:,1:fmax+1,:]\n",
    "\n",
    "\n",
    "for i in range(len(data_valid)):\n",
    "    valid_a.append(data_valid[i].a)\n",
    "    valid_b.append(data_valid[i].b)\n",
    "    valid_labels.append(data_valid[i].label)\n",
    "    valid_srf.append(data_valid[i].srf)\n",
    "x_valid_a = np.array(valid_a) \n",
    "x_valid_b = np.array(valid_b)\n",
    "x_valid_srf = np.array(valid_srf)\n",
    "y_valid_encoded = np.array(valid_labels)[:,1:fmax+1,:]\n",
    "\n",
    "\n",
    "for i in range(len(data_test)):\n",
    "    test_a.append(data_test[i].a)\n",
    "    test_b.append(data_test[i].b)\n",
    "    test_labels.append(data_test[i].label)\n",
    "    test_srf.append(data_test[i].srf)\n",
    "x_test_a = np.array(test_a) \n",
    "x_test_b = np.array(test_b)\n",
    "x_test_srf = np.array(test_srf)\n",
    "y_test_encoded = np.array(test_labels)[:,1:fmax+1,:]\n",
    "\n",
    "#normalize the s-parameters for each frequency point\n",
    "for z in range(fmax):\n",
    "    for i in range(12):\n",
    "        s_max[z,i] = max(max(y_train_encoded[:,z,i]),max(y_valid_encoded[:,z,i]),max(y_test_encoded[:,z,i]))\n",
    "        s_min[z,i] = min(min(y_train_encoded[:,z,i]),min(y_valid_encoded[:,z,i]),min(y_test_encoded[:,z,i]))\n",
    "        srange[z,i] = s_max[z,i]-s_min[z,i]\n",
    "    \n",
    "    for i in range(12):\n",
    "        y_train_encoded[:,z,i] = 2*(y_train_encoded[:,z,i]-s_min[z,i])/srange[z,i]-1\n",
    "\n",
    "    for i in range(12):\n",
    "        y_valid_encoded[:,z,i] = 2*(y_valid_encoded[:,z,i]-s_min[z,i])/srange[z,i]-1\n",
    "    \n",
    "    for i in range(12):\n",
    "        y_test_encoded[:,z,i] = 2*(y_test_encoded[:,z,i]-s_min[z,i])/srange[z,i]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d258298-4352-4221-a7c8-e84021860541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- numerically safe attention masks -----------------------------\n",
    "def _to_additive_attn_mask(score: torch.Tensor, cap: float = 10.0):\n",
    "    \"\"\"\n",
    "    Convert arbitrary 'score' to a numerically safe additive mask in [-cap, 0]:\n",
    "      mask = score - max(score, dim=-1), so mask <= 0 everywhere,\n",
    "      then clamp to [-cap, 0] to bound magnitude under AMP.\n",
    "    score: [B, Lq, Lk] (float/half)\n",
    "    returns: [B, Lq, Lk] (float32) in [-cap, 0]\n",
    "    \"\"\"\n",
    "    s = score.detach().float()\n",
    "    s = s - s.max(dim=-1, keepdim=True).values          # <= 0 per row\n",
    "    s = s.clamp(-cap, 0.0)\n",
    "    return s\n",
    "\n",
    "def _safe_bias(mask: torch.Tensor, n_heads: int):\n",
    "    \"\"\"\n",
    "    mask: [B, Lq, Lk] additive mask in [-cap, 0] (float32).\n",
    "    Returns [B*nH, Lq, Lk] float32, repeated per head.\n",
    "    \"\"\"\n",
    "    return mask.repeat_interleave(n_heads, dim=0)\n",
    "\n",
    "# ----------------------------- transformer blocks -----------------------------\n",
    "class EdgeAwareBlock(nn.Module):\n",
    "    \"\"\"Self-attention with additive geodesic/ohmic bias (safe for fp16).\"\"\"\n",
    "    def __init__(self, d_model: int, n_heads: int = 8, dropout: float = 0.0, ff_mult: int = 4):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ff  = nn.Sequential(nn.Linear(d_model, ff_mult * d_model), nn.GELU(),\n",
    "                                 nn.Linear(ff_mult * d_model, d_model))\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, attn_bias: torch.Tensor):\n",
    "        \"\"\"\n",
    "        X: [B,L,D]\n",
    "        attn_bias: [B,L,L] float32, **must already be in [-cap, 0]** (use _to_additive_attn_mask upstream)\n",
    "        \"\"\"\n",
    "        bias = _safe_bias(attn_bias, self.n_heads)       # [B*H,L,L] float32\n",
    "        QKV = self.ln1(X)\n",
    "        Y,_ = self.attn(QKV, QKV, QKV, attn_mask=bias)   # stable additive mask\n",
    "        X = X + self.drop(Y)\n",
    "        X = X + self.drop(self.ff(self.ln2(X)))\n",
    "        return X\n",
    "\n",
    "class EdgeAwareEncoder(nn.Module):\n",
    "    def __init__(self, d_model: int, n_layers: int = 4, n_heads: int = 8, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EdgeAwareBlock(d_model, n_heads, dropout) for _ in range(n_layers)])\n",
    "        self.out_ln = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, attn_mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        X: [B,L,D]\n",
    "        attn_mask: [B,L,L] float32, in [-cap, 0]\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            X = layer(X, attn_mask)\n",
    "        return self.out_ln(X)\n",
    "\n",
    "class BipartiteCrossAttentionFusion(nn.Module):\n",
    "    \"\"\"Primary↔Secondary bidirectional cross-attention with coupling-aware mask.\"\"\"\n",
    "    def __init__(self, d_model: int, n_heads: int = 8, dropout: float = 0.0, k_top: int = 16):\n",
    "        super().__init__()\n",
    "        self.k_top = k_top\n",
    "        self.h = n_heads\n",
    "        self.attn_ps = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)  # P<-S\n",
    "        self.attn_sp = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)  # S<-P\n",
    "        self.ln_p1 = nn.LayerNorm(d_model); self.ln_s1 = nn.LayerNorm(d_model)\n",
    "        self.ln_p2 = nn.LayerNorm(d_model); self.ln_s2 = nn.LayerNorm(d_model)\n",
    "        self.ff_p  = nn.Sequential(nn.Linear(d_model, 4*d_model), nn.GELU(), nn.Linear(4*d_model, d_model))\n",
    "        self.ff_s  = nn.Sequential(nn.Linear(d_model, 4*d_model), nn.GELU(), nn.Linear(4*d_model, d_model))\n",
    "        self.drop  = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, Zp: torch.Tensor, Zs: torch.Tensor, feats_p7: torch.Tensor, feats_s7: torch.Tensor):\n",
    "        # Build raw scores\n",
    "        score_ps = build_intercoil_bias(feats_p7, feats_s7, k_top=self.k_top)  # [B,Lp,Ls] (fp32)\n",
    "        score_sp = build_intercoil_bias(feats_s7, feats_p7, k_top=self.k_top)  # [B,Ls,Lp] (fp32)\n",
    "\n",
    "        # Convert to **non-positive** additive masks (numerically stable under AMP)\n",
    "        mask_ps = _to_additive_attn_mask(score_ps, cap=10.0)  # [-10, 0], [B,Lp,Ls]\n",
    "        mask_sp = _to_additive_attn_mask(score_sp, cap=10.0)  # [-10, 0], [B,Ls,Lp]\n",
    "\n",
    "        Mps = _safe_bias(mask_ps, self.h)   # [B*h, Lp, Ls]\n",
    "        Msp = _safe_bias(mask_sp, self.h)   # [B*h, Ls, Lp]\n",
    "\n",
    "        P, S = self.ln_p1(Zp), self.ln_s1(Zs)\n",
    "        attn_ps,_ = self.attn_ps(P, S, S, attn_mask=Mps)  # P attends to S\n",
    "        Zp = Zp + self.drop(attn_ps); Zp = Zp + self.drop(self.ff_p(self.ln_p2(Zp)))\n",
    "\n",
    "        attn_sp,_ = self.attn_sp(S, P, P, attn_mask=Msp)  # S attends to P\n",
    "        Zs = Zs + self.drop(attn_sp); Zs = Zs + self.drop(self.ff_s(self.ln_s2(Zs)))\n",
    "        return Zp, Zs\n",
    "\n",
    "# ----------------------------- main encoder -----------------------------\n",
    "class SelfSupervisedGraphEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Produces a single sequence of tokens encoding: ports(primary/secondary), coupling latents,\n",
    "    all segment tokens (P + S), and one global token. Role/coil/process embeddings disambiguate.\n",
    "    \"\"\"\n",
    "    ROLE_SEGMENT, ROLE_PORT, ROLE_COUPLING, ROLE_GLOBAL = 0, 1, 2, 3\n",
    "    COIL_NONE, COIL_PRIMARY, COIL_SECONDARY = 0, 1, 2\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_model: int = 256,\n",
    "                 num_ports_per_coil: int = 2,\n",
    "                 n_coupling_tokens: int = 16,\n",
    "                 n_fuse_heads: int = 8,\n",
    "                 fuse_k_top: int = 16,\n",
    "                 fuse_dropout: float = 0.0,\n",
    "                 n_intra_layers: int = 4,\n",
    "                 n_intra_heads: int = 8,\n",
    "                 intra_dropout: float = 0.0,\n",
    "                 post_concat_layers: int = 0,\n",
    "                 post_concat_heads: int = 4,\n",
    "                 post_concat_dropout: float = 0.0,\n",
    "                 proc_dim: int = 4):\n",
    "        super().__init__()\n",
    "        self.d = d_model\n",
    "        self.num_ports = num_ports_per_coil\n",
    "\n",
    "        # We don't know enriched input dim until first call\n",
    "        self.to_embed_p = nn.LazyLinear(d_model)\n",
    "        self.to_embed_s = nn.LazyLinear(d_model)\n",
    "\n",
    "        self.enc_p = EdgeAwareEncoder(d_model, n_layers=n_intra_layers, n_heads=n_intra_heads, dropout=intra_dropout)\n",
    "        self.enc_s = EdgeAwareEncoder(d_model, n_layers=n_intra_layers, n_heads=n_intra_heads, dropout=intra_dropout)\n",
    "\n",
    "        self.fusion = BipartiteCrossAttentionFusion(d_model, n_heads=n_fuse_heads,\n",
    "                                                    dropout=fuse_dropout, k_top=fuse_k_top)\n",
    "\n",
    "        self.port_pool_p = QueryPool(d_model, n_tokens=num_ports_per_coil, n_heads=4)\n",
    "        self.port_pool_s = QueryPool(d_model, n_tokens=num_ports_per_coil, n_heads=4)\n",
    "        self.couple_pool = CouplingBottleneck(d_model, n_tokens=n_coupling_tokens, n_heads=8)\n",
    "        self.global_pool = QueryPool(d_model, n_tokens=1, n_heads=4)\n",
    "\n",
    "        self.role_embed = nn.Embedding(4, d_model)\n",
    "        self.coil_embed = nn.Embedding(3, d_model)\n",
    "        self.proc_proj  = nn.Linear(proc_dim, d_model)\n",
    "\n",
    "        self.post_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=post_concat_heads,\n",
    "                                       dim_feedforward=4*d_model, dropout=post_concat_dropout,\n",
    "                                       batch_first=True, activation=\"gelu\", norm_first=True)\n",
    "            for _ in range(post_concat_layers)\n",
    "        ])\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_role_coil(X: torch.Tensor, role_id: int, coil_id: int,\n",
    "                       role_embed: nn.Embedding, coil_embed: nn.Embedding, proc_tok: torch.Tensor = None):\n",
    "        B, L, D = X.shape\n",
    "        X = X + role_embed.weight[role_id].view(1, 1, D)\n",
    "        X = X + coil_embed.weight[coil_id].view(1, 1, D)\n",
    "        if proc_tok is not None:\n",
    "            X = X + proc_tok.unsqueeze(1)\n",
    "        return X\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _build_masks(self, B: int, sizes, device):\n",
    "        Pp, Ps, C, Lp, Ls = sizes\n",
    "        Ltot = Pp + Ps + C + Lp + Ls + 1\n",
    "        masks = {\n",
    "            \"ports_mask\":    torch.zeros(B, Ltot, dtype=torch.bool, device=device),\n",
    "            \"coupling_mask\": torch.zeros(B, Ltot, dtype=torch.bool, device=device),\n",
    "            \"segP_mask\":     torch.zeros(B, Ltot, dtype=torch.bool, device=device),\n",
    "            \"segS_mask\":     torch.zeros(B, Ltot, dtype=torch.bool, device=device),\n",
    "            \"global_mask\":   torch.zeros(B, Ltot, dtype=torch.bool, device=device),\n",
    "        }\n",
    "        slices = {}\n",
    "        start = 0\n",
    "        slices[\"ports_slice\"]    = slice(start, start + Pp + Ps);  start += Pp + Ps\n",
    "        masks[\"ports_mask\"][:, slices[\"ports_slice\"]] = True\n",
    "        slices[\"coupling_slice\"] = slice(start, start + C);        start += C\n",
    "        masks[\"coupling_mask\"][:, slices[\"coupling_slice\"]] = True\n",
    "        slices[\"segP_slice\"]     = slice(start, start + Lp);       start += Lp\n",
    "        masks[\"segP_mask\"][:, slices[\"segP_slice\"]] = True\n",
    "        slices[\"segS_slice\"]     = slice(start, start + Ls);       start += Ls\n",
    "        masks[\"segS_mask\"][:, slices[\"segS_slice\"]] = True\n",
    "        slices[\"global_slice\"]   = slice(start, start + 1)\n",
    "        masks[\"global_mask\"][:, slices[\"global_slice\"]] = True\n",
    "        return masks, slices\n",
    "\n",
    "    def forward(self, inp1_7: torch.Tensor, inp2_7: torch.Tensor, proc_vec: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        inp1_7, inp2_7: [B, L, 7]   (primary, secondary)\n",
    "        proc_vec: [B, 4] = [t_metal, h_sub, eps_r, rho_sheet] (optional; defaults provided)\n",
    "        Returns: tokens [B, Ltot, D], masks dict, slices dict\n",
    "        \"\"\"\n",
    "        B = inp1_7.size(0)\n",
    "        dev = inp1_7.device\n",
    "        if proc_vec is None:\n",
    "            proc_vec = torch.tensor([[2e-6, 3e-6, 3.9, 0.05]], dtype=inp1_7.dtype, device=dev).repeat(B, 1)\n",
    "        proc_tok = self.proc_proj(proc_vec)  # [B,D]\n",
    "\n",
    "        # enrich & embed\n",
    "        feats_p, _ = enrich_segment_features(inp1_7, proc=dict(\n",
    "            t_metal=float(proc_vec[0,0].item()),\n",
    "            h_sub=float(proc_vec[0,1].item()),\n",
    "            eps_r=float(proc_vec[0,2].item()),\n",
    "            rho_sheet=float(proc_vec[0,3].item())\n",
    "        ))\n",
    "        feats_s, _ = enrich_segment_features(inp2_7, proc=dict(\n",
    "            t_metal=float(proc_vec[0,0].item()),\n",
    "            h_sub=float(proc_vec[0,1].item()),\n",
    "            eps_r=float(proc_vec[0,2].item()),\n",
    "            rho_sheet=float(proc_vec[0,3].item())\n",
    "        ))\n",
    "\n",
    "        Zp = self.to_embed_p(feats_p)  # [B,Lp,D]\n",
    "        Zs = self.to_embed_s(feats_s)  # [B,Ls,D]\n",
    "\n",
    "        # -------- Intra-coil encoders with SAFE additive masks --------\n",
    "        raw_p = build_ohmic_bias(inp1_7)                    # [B,Lp,Lp] (fp32, can be <= 0)\n",
    "        raw_s = build_ohmic_bias(inp2_7)                    # [B,Ls,Ls]\n",
    "        mask_p = _to_additive_attn_mask(raw_p, cap=10.0)    # [-10, 0]\n",
    "        mask_s = _to_additive_attn_mask(raw_s, cap=10.0)    # [-10, 0]\n",
    "        Zp = self.enc_p(Zp, mask_p)\n",
    "        Zs = self.enc_s(Zs, mask_s)\n",
    "\n",
    "        # -------- Cross-coil physics-aware fusion (SAFE masks inside) --------\n",
    "        Zp, Zs = self.fusion(Zp, Zs, inp1_7, inp2_7)\n",
    "\n",
    "        # pools\n",
    "        ports_p  = self.port_pool_p(Zp)                  # [B,Pp,D]\n",
    "        ports_s  = self.port_pool_s(Zs)                  # [B,Ps,D]\n",
    "        coupling = self.couple_pool(Zp, Zs)              # [B,C,D]\n",
    "        global_t = self.global_pool(torch.cat([Zp, Zs], dim=1))  # [B,1,D]\n",
    "\n",
    "        # role/coil/process tagging\n",
    "        Zp        = self._add_role_coil(Zp,       self.ROLE_SEGMENT,  self.COIL_PRIMARY,  self.role_embed, self.coil_embed, proc_tok)\n",
    "        Zs        = self._add_role_coil(Zs,       self.ROLE_SEGMENT,  self.COIL_SECONDARY,self.role_embed, self.coil_embed, proc_tok)\n",
    "        ports_p   = self._add_role_coil(ports_p,  self.ROLE_PORT,     self.COIL_PRIMARY,  self.role_embed, self.coil_embed, proc_tok)\n",
    "        ports_s   = self._add_role_coil(ports_s,  self.ROLE_PORT,     self.COIL_SECONDARY,self.role_embed, self.coil_embed, proc_tok)\n",
    "        coupling  = self._add_role_coil(coupling, self.ROLE_COUPLING, self.COIL_NONE,     self.role_embed, self.coil_embed, proc_tok)\n",
    "        global_t  = self._add_role_coil(global_t, self.ROLE_GLOBAL,   self.COIL_NONE,     self.role_embed, self.coil_embed, proc_tok)\n",
    "\n",
    "        # concatenate full sequence\n",
    "        tokens = torch.cat([ports_p, ports_s, coupling, Zp, Zs, global_t], dim=1)  # [B,Ltot,D]\n",
    "        for layer in self.post_layers:\n",
    "            tokens = layer(tokens)\n",
    "\n",
    "        sizes = (ports_p.size(1), ports_s.size(1), coupling.size(1), Zp.size(1), Zs.size(1))\n",
    "        masks, slices = self._build_masks(B, sizes, device=tokens.device)\n",
    "        return tokens, masks, slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c282d97-8fb6-4bc7-adea-bce6ce109406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    Lf = torch.sqrt(torch.mean((y_true - y_pred) ** 2, dim=1))  # Compute RMSE across feature axis\n",
    "    return torch.log(torch.mean(Lf))  # Compute log of mean RMSE\n",
    "    #return (torch.mean(Lf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01bb9df8-99ec-4e73-be95-ba760f2a737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSSLDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Required:\n",
    "      p_segs: [N, Lp, 7]\n",
    "      s_segs: [N, Ls, 7]\n",
    "    Optional (omit or pass None to skip related losses):\n",
    "      proc:    [N,4]  -> [t_metal, h_sub, eps_r, rho_sheet]\n",
    "      p_ports: [N,Pp,2]\n",
    "      s_ports: [N,Ps,2]\n",
    "      image:   [N,C,H,W]\n",
    "      C_target:[N,2P,2P]\n",
    "    \"\"\"\n",
    "    def __init__(self, p_segs, s_segs, proc=None, p_ports=None, s_ports=None, image=None, C_target=None):\n",
    "        self.p_segs = p_segs\n",
    "        self.s_segs = s_segs\n",
    "        self.proc = proc\n",
    "        self.p_ports = p_ports\n",
    "        self.s_ports = s_ports\n",
    "        self.image = image\n",
    "        self.C_target = C_target\n",
    "    def __len__(self): return self.p_segs.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        d = {\"p_segs\": self.p_segs[i], \"s_segs\": self.s_segs[i]}\n",
    "        if self.proc is not None:     d[\"proc\"] = self.proc[i]\n",
    "        if self.p_ports is not None:  d[\"p_ports\"] = self.p_ports[i]\n",
    "        if self.s_ports is not None:  d[\"s_ports\"] = self.s_ports[i]\n",
    "        if self.image is not None:    d[\"image\"] = self.image[i]\n",
    "        if self.C_target is not None: d[\"C_target\"] = self.C_target[i]\n",
    "        return d\n",
    "\n",
    "# If your data are NumPy arrays, convert them first:\n",
    "# x_train_a: [N, Lp, 7], x_train_b: [N, Ls, 7]\n",
    "p_segs = torch.from_numpy(x_train_a).float()\n",
    "s_segs = torch.from_numpy(x_train_b).float()\n",
    "\n",
    "# Optional extras (set to None if you don't have them yet)\n",
    "proc     = None           # torch.tensor([...],[N,4]).float()\n",
    "p_ports  = None           # torch.tensor([...],[N,Pp,2]).float()\n",
    "s_ports  = None           # torch.tensor([...],[N,Ps,2]).float()\n",
    "image    = None           # torch.tensor([...],[N,C,H,W]).float()\n",
    "C_target = None           # torch.tensor([...],[N,2P,2P]).float()\n",
    "\n",
    "dataset = GraphSSLDataset(p_segs, s_segs, proc, p_ports, s_ports, image, C_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0d2a650-7d8e-4352-ba95-b5de2e6af247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repro/compute\n",
    "SEED = 1337\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "AMP_ENABLED = (device.type == \"cuda\")\n",
    "\n",
    "# Data loading\n",
    "batch_size         = 32\n",
    "val_frac           = 0.20\n",
    "num_workers_train  = 4\n",
    "num_workers_val    = 2\n",
    "drop_last_train    = True\n",
    "drop_last_val      = False\n",
    "\n",
    "# Optimization & schedule\n",
    "epochs        = 120\n",
    "learning_rate = 1e-3\n",
    "weight_decay  = 0.05\n",
    "grad_clip     = 1.0\n",
    "lr_decay_base   = 0.95\n",
    "lr_decay_period = 20  # epochs-equivalent in the lambda\n",
    "def lr_lambda(epoch): return lr_decay_base ** (epoch / lr_decay_period)\n",
    "\n",
    "# Logging / checkpoints\n",
    "PRINT_EVERY = 20\n",
    "ckpt_path   = \"best_ssl.pt\"\n",
    "\n",
    "# (Optional) SSL loss weights for SSLTrainer (if used elsewhere)\n",
    "ssl_loss_weights = dict(reach=0.25, proxy=0.25, equiv=0.15, d4=0.15, C=0.10, clip=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db1c8e0f-ade5-4f82-9c8f-04115919483c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3789183/3731822080.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
      "/tmp/ipykernel_3789183/3731822080.py:64: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/120]  TRAIN loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   |   VAL loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   (best_val=0.0000)\n",
      "[Epoch 20/120]  TRAIN loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   |   VAL loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   (best_val=0.0000)\n",
      "[Epoch 40/120]  TRAIN loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   |   VAL loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   (best_val=0.0000)\n",
      "[Epoch 60/120]  TRAIN loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   |   VAL loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   (best_val=0.0000)\n",
      "[Epoch 80/120]  TRAIN loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   |   VAL loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   (best_val=0.0000)\n",
      "[Epoch 100/120]  TRAIN loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   |   VAL loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   (best_val=0.0000)\n",
      "[Epoch 120/120]  TRAIN loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   |   VAL loss:0.0000 reach:0.0000 proxy:0.0000 equiv:0.0000 d4:0.0000 C:0.0000 clip:0.0000   (best_val=0.0000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================== VALIDATION-ENABLED SSL TRAINING ==========================\n",
    "PRINT_EVERY = 20  # print every 20 epochs\n",
    "\n",
    "# --- split your dataset into train/val (80/20 by default) ---\n",
    "val_frac = 0.2\n",
    "N = len(dataset)\n",
    "n_val = max(1, int(N * val_frac))\n",
    "n_train = N - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
    "                                           drop_last=True, num_workers=4)\n",
    "val_loader   = torch.utils.data.DataLoader(val_set,   batch_size=batch_size, shuffle=False,\n",
    "                                           drop_last=False, num_workers=2)\n",
    "\n",
    "# --- optimizer/scheduler as before ---\n",
    "optimizer = optim.AdamW(ssl.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "def lr_lambda(epoch): return 0.95 ** (epoch / 20)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
    "\n",
    "def _agg_dict(keys):\n",
    "    return {k: 0.0 for k in keys}\n",
    "\n",
    "def _normalize_agg(d, denom):\n",
    "    for k in d:\n",
    "        d[k] /= max(1, denom)\n",
    "\n",
    "def evaluate_ssl(model, loader):\n",
    "    model.eval()\n",
    "    keys = [\"loss\",\"reach\",\"proxy\",\"equiv\",\"d4\",\"C\",\"clip\"]\n",
    "    agg = {k: 0.0 for k in keys}\n",
    "    steps = 0\n",
    "    skipped = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            for k, v in list(batch.items()):\n",
    "                if torch.is_tensor(v):\n",
    "                    batch[k] = v.to(device, non_blocking=True)\n",
    "            loss, logs = model.forward_one(batch)\n",
    "            if not torch.isfinite(loss):\n",
    "                skipped += 1\n",
    "                continue\n",
    "            steps += 1\n",
    "            for k in keys:\n",
    "                val = logs.get(k, 0.0)\n",
    "                val = float(val) if isinstance(val, (float, int)) else float(torch.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "                agg[k] += val\n",
    "    denom = max(1, steps)\n",
    "    for k in agg:\n",
    "        agg[k] /= denom\n",
    "    # keep signature the same (dict), but include extra info as optional fields\n",
    "    agg[\"steps\"] = steps\n",
    "    agg[\"skipped\"] = skipped\n",
    "    return agg\n",
    "\n",
    "def train_ssl_model(model, optimizer, scheduler, num_epochs, train_loader, val_loader, ckpt_path=\"best_ssl.pt\"):\n",
    "    best_val = float(\"inf\")\n",
    "    keys = [\"loss\",\"reach\",\"proxy\",\"equiv\",\"d4\",\"C\",\"clip\"]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_agg = {k: 0.0 for k in keys}\n",
    "        steps = 0\n",
    "        skipped_train = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            for k, v in list(batch.items()):\n",
    "                if torch.is_tensor(v):\n",
    "                    batch[k] = v.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "                loss, logs = model.forward_one(batch)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                skipped_train += 1\n",
    "                continue\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            steps += 1\n",
    "            for k in keys:\n",
    "                val = logs.get(k, 0.0)\n",
    "                val = float(val) if isinstance(val, (float, int)) else float(torch.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "                train_agg[k] += val\n",
    "\n",
    "        scheduler.step()\n",
    "        denom = max(1, steps)\n",
    "        for k in train_agg:\n",
    "            train_agg[k] /= denom\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        val_agg = evaluate_ssl(model, val_loader)\n",
    "        val_total = float(val_agg.get(\"loss\", float(\"inf\")))\n",
    "        val_steps = int(val_agg.get(\"steps\", 0))\n",
    "        val_skipped = int(val_agg.get(\"skipped\", 0))\n",
    "\n",
    "        # ---- CHECKPOINT ----\n",
    "        if torch.isfinite(torch.tensor(val_total)) and (val_total < best_val):\n",
    "            best_val = val_total\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"scheduler\": scheduler.state_dict(),\n",
    "                \"epoch\": epoch+1,\n",
    "                \"best_val\": best_val\n",
    "            }, ckpt_path)\n",
    "\n",
    "        # ---- PRINT: epoch 1, every PRINT_EVERY, and final epoch ----\n",
    "        is_print_epoch = ((epoch + 1) % PRINT_EVERY == 0) or (epoch == 0) or ((epoch + 1) == num_epochs)\n",
    "        if is_print_epoch:\n",
    "            lr = optimizer.param_groups[0].get(\"lr\", None)\n",
    "            tr = \" \".join([f\"{k}:{train_agg[k]:.4f}\" for k in keys])\n",
    "            va = \" \".join([f\"{k}:{float(val_agg.get(k, 0.0)):.4f}\" for k in keys])\n",
    "            extras = []\n",
    "            if lr is not None:\n",
    "                extras.append(f\"lr:{lr:.3e}\")\n",
    "            extras.append(f\"steps:{steps} skipped:{skipped_train}\")\n",
    "            extras.append(f\"val_steps:{val_steps} val_skipped:{val_skipped}\")\n",
    "            extra_str = \"  [\" + \" | \".join(extras) + \"]\"\n",
    "            print(f\"[Epoch {epoch+1}/{num_epochs}]  TRAIN {tr}   |   VAL {va}   (best_val={best_val:.4f}){extra_str}\", flush=True)\n",
    "\n",
    "# --- kick off training with validation tracking ---\n",
    "train_ssl_model(ssl, optimizer, scheduler, epochs, train_loader, val_loader, ckpt_path=\"best_ssl.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba03e07-7eb1-4f2f-afa7-8bb3a66a4a14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(np.shape(\u001b[43mx1\u001b[49m))\n\u001b[32m      3\u001b[39m summary(model, input_size=[(\u001b[32m1\u001b[39m, \u001b[32m51\u001b[39m, \u001b[32m7\u001b[39m),(\u001b[32m1\u001b[39m,\u001b[32m51\u001b[39m,\u001b[32m7\u001b[39m)])\n",
      "\u001b[31mNameError\u001b[39m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "print(np.shape(x1))\n",
    "summary(model, input_size=[(1, 51, 7),(1,51,7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b815d6-b935-4583-a76d-c436e826a55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
